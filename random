series_meta = gilt_df.drop_duplicates(["series_id","maturity_year"])
def pick_series(row):
    cands = series_meta[series_meta["maturity_year"]==row["maturity_year"]]
    return cands.iloc[0]["series_id"] if not cands.empty else None
calendar_df["series_id"] = calendar_df.apply(pick_series, axis=1)
cal_matched = calendar_df.dropna(subset=["series_id"])


panel = []
for _,a in cal_matched.iterrows():
    g = gilt_df[gilt_df["series_id"]==a["series_id"]].copy()
    g = g.sort_values("date")
    dates = list(g["date"].unique())
    if a["auction_dt"] not in dates: continue
    pos = dates.index(a["auction_dt"])
    for k,d in enumerate(dates):
        rel = k-pos
        if -10 <= rel <= 10:
            y = g.loc[g["date"]==d,"yld"].mean()
            panel.append({
                "auction_dt": a["auction_dt"],
                "series_id": a["series_id"],
                "date": d,
                "rel_day": rel,
                "y_close": y,
                "bucket": a["bucket"]
            })
panel = pd.DataFrame(panel)




avg_yld = (panel.groupby(["bucket","rel_day"])["y_close"]
                 .mean().reset_index()
                 .pivot(index="rel_day", columns="bucket", values="y_close"))





def concessions(df):
    sub = df[df["rel_day"].between(-10,10)]
    grp = sub.groupby(["auction_dt","series_id"])
    t_5 = grp.apply(lambda g: g.loc[g["rel_day"]==-5,"y_close"].mean())
    t_1 = grp.apply(lambda g: g.loc[g["rel_day"]==-1,"y_close"].mean())
    t0  = grp.apply(lambda g: g.loc[g["rel_day"]==0,"y_close"].mean())
    p5  = grp.apply(lambda g: g.loc[g["rel_day"]==5,"y_close"].mean())
    return pd.DataFrame({
        "cons_pre_5d": t0 - t_5,
        "cons_pre_1d": t0 - t_1,
        "reversal_5d": p5 - t0
    }).reset_index()

cons_yld = concessions(panel)
bucket_map = panel.drop_duplicates(["auction_dt","series_id"])[["auction_dt","series_id","bucket"]]
summary = cons_yld.merge(bucket_map,on=["auction_dt","series_id"]).groupby("bucket").mean()


print("\nConcession summary by bucket (levels are in percentage points; Ã—100 for bp):")
print(summary.round(4))

# Optional: also show distribution per bucket
dist = (per_auction.merge(bucket_map, on=["auction_dt","series_id"], how="left")
                  .groupby("bucket")[["cons_pre_5d","cons_pre_1d","reversal_5d"]]
                  .describe())
